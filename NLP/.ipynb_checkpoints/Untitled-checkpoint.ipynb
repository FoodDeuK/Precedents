{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b8ad5469",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'simple_preprecess' from 'gensim.utils' (C:\\ProgramData\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\gensim\\utils.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Input \u001b[1;32mIn [2]\u001b[0m, in \u001b[0;36m<cell line: 9>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mgensim\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mgensim\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcorpora\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mcorpora\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgensim\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m simple_preprecess\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgensim\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CoherenceModel\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtqdm\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m trange\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'simple_preprecess' from 'gensim.utils' (C:\\ProgramData\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\gensim\\utils.py)"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "\n",
    "from konlpy.tag import Okt\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "from tqdm import trange\n",
    "\n",
    "import sqlite3\n",
    "\n",
    "import spacy\n",
    "\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef65398f",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = sqlite3.connect(\"../Precedents.db\")\n",
    "curs = conn.cursor()\n",
    "\n",
    "sql = \"SELECT * FROM Precedents_IC\"\n",
    "curs.execute(sql)\n",
    "\n",
    "fetchedData = curs.fetchall()\n",
    "length = len(fetchedData)\n",
    "fetchedData = [list(fetchedData[x]) for x in range(length)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6de9cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_word=[]\n",
    "\n",
    "for x in trange(length):\n",
    "    filepath = \"C:/Temp/Cases/판례내용/{}.txt\".format(fetchedData[x][0])\n",
    "    if os.path.getsize(filepath) != 0:\n",
    "        with open(filepath) as file:\n",
    "            doc = file.read()\n",
    "        try:\n",
    "            data_word.append(okt.nouns(doc))\n",
    "        except Exception as e:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee6eb95f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data_word[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddb61109",
   "metadata": {},
   "outputs": [],
   "source": [
    "id2word=corpora.Dictionary(data_word)\n",
    "id2word.filter_extremes(no_below = 20)\n",
    "texts = data_word\n",
    "corpus = [id2word.doc2bow(text) for text in texts]\n",
    "\n",
    "mallet_path = '../mallet-2.0.8/bin/mallet'\n",
    "ldamallet = gensim.models.wrappers.LdaMallet(mallet_path, corpus = corpus, num_topics = 10, id2word = id2word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d39425",
   "metadata": {},
   "outputs": [],
   "source": [
    "coherence_model_ldamallet = CoherenceModel(model=ldamallet, texts=texts, dictionary=id2word, coherence='c_v')\n",
    "coherence_ldamallet = coherence_model_ldamallet.get_coherence()\n",
    "\n",
    "def compute_coherence_values(dictionary, corpus, texts, limit, start=4, step=2):\n",
    "\n",
    "    coherence_values = []\n",
    "    model_list = []\n",
    "    for num_topics in range(start, limit, step):\n",
    "        model = gensim.models.wrappers.LdaMallet(mallet_path, corpus=corpus, num_topics=num_topics, id2word=id2word)\n",
    "        model_list.append(model)\n",
    "        coherencemodel = CoherenceModel(model=model, texts=data_word, dictionary=dictionary, coherence='c_v')\n",
    "        coherence_values.append(coherencemodel.get_coherence())\n",
    "\n",
    "    return model_list, coherence_values\n",
    "\n",
    "\n",
    "\n",
    "# Can take a long time to run.\n",
    "model_list, coherence_values = compute_coherence_values(dictionary=id2word, corpus=corpus, texts=texts, start=4, limit=21, step=2)\n",
    "\n",
    "limit=21; start=4; step=2;\n",
    "x = range(start, limit, step)\n",
    "topic_num = 0\n",
    "count = 0\n",
    "max_coherence = 0\n",
    "for m, cv in zip(x, coherence_values):\n",
    "    print(\"Num Topics =\", m, \" has Coherence Value of\", cv)\n",
    "    coherence = cv\n",
    "    if coherence >= max_coherence:\n",
    "        max_coherence = coherence\n",
    "        topic_num = m\n",
    "        model_list_num = count   \n",
    "    count = count+1\n",
    "        \n",
    "# Select the model and print the topics\n",
    "optimal_model = model_list[model_list_num]\n",
    "model_topics = optimal_model.show_topics(formatted=False)\n",
    "#print(optimal_model.print_topics(num_words=10))\n",
    "\n",
    "def format_topics_sentences(ldamodel=optimal_model, corpus=corpus, texts=texts):\n",
    "    # Init output\n",
    "    sent_topics_df = pd.DataFrame()\n",
    "\n",
    "    # Get main topic in each document\n",
    "    #ldamodel[corpus]: lda_model에 corpus를 넣어 각 토픽 당 확률을 알 수 있음\n",
    "    for i, row in enumerate(ldamodel[corpus]):\n",
    "        row = sorted(row, key=lambda x: (x[1]), reverse=True)\n",
    "        # Get the Dominant topic, Perc Contribution and Keywords for each document\n",
    "        for j, (topic_num, prop_topic) in enumerate(row):\n",
    "            if j == 0:  # => dominant topic\n",
    "                wp = ldamodel.show_topic(topic_num,topn=10)\n",
    "                topic_keywords = \", \".join([word for word, prop in wp])\n",
    "                sent_topics_df = sent_topics_df.append(pd.Series([int(topic_num), round(prop_topic,4), topic_keywords]), ignore_index=True)\n",
    "            else:\n",
    "                break\n",
    "    sent_topics_df.columns = ['Dominant_Topic', 'Perc_Contribution', 'Topic_Keywords']\n",
    "    print(type(sent_topics_df))\n",
    "\n",
    "    # Add original text to the end of the output\n",
    "    #contents = pd.Series(texts)\n",
    "    #sent_topics_df = pd.concat([sent_topics_df, contents], axis=1)\n",
    "    sent_topics_df = pd.concat([sent_topics_df, Data['text'],Data['timestamp'],Data['tweet_url'],Data['screen_name'],Data['label']], axis=1)\n",
    "    return(sent_topics_df)\n",
    "\n",
    "\n",
    "df_topic_sents_keywords = format_topics_sentences(ldamodel=optimal_model, corpus=corpus, texts=Data_list)\n",
    "\n",
    "# Format\n",
    "df_topic_tweet = df_topic_sents_keywords.reset_index()\n",
    "df_topic_tweet.columns = ['Document_No', 'Dominant_Topic', 'Topic_Perc_Contrib', 'Keywords', 'Text','Timestamp', 'Tweet_url','Screen_name','label']\n",
    "\n",
    "# Show각 문서에 대한 토픽\n",
    "#df_dominant_topic=df_dominant_topic.sort_values(by=['Dominant_Topic'])\n",
    "#df_topic_tweet\n",
    "\n",
    "\n",
    "# Group top 5 sentences under each topic\n",
    "sent_topics_sorteddf_mallet = pd.DataFrame()\n",
    "\n",
    "sent_topics_outdf_grpd = df_topic_sents_keywords.groupby('Dominant_Topic')\n",
    "\n",
    "for i, grp in sent_topics_outdf_grpd:\n",
    "    sent_topics_sorteddf_mallet = pd.concat([sent_topics_sorteddf_mallet, \n",
    "                                             grp.sort_values(['Perc_Contribution'], ascending=[0]).head(1)], \n",
    "                                            axis=0)\n",
    "\n",
    "# Reset Index    \n",
    "sent_topics_sorteddf_mallet.reset_index(drop=True, inplace=True)\n",
    "\n",
    "\n",
    "topic_counts = df_topic_sents_keywords['Dominant_Topic'].value_counts()\n",
    "topic_counts.sort_index(inplace=True)\n",
    "\n",
    "topic_contribution = round(topic_counts/topic_counts.sum(), 4)\n",
    "topic_contribution\n",
    "\n",
    "lda_inform = pd.concat([sent_topics_sorteddf_mallet, topic_counts, topic_contribution], axis=1)\n",
    "lda_inform.columns=[\"Topic_Num\", \"Topic_Perc_Contrib\", \"Keywords\", \"Text\", \"timestamp\", \"tweet_url\",\"screen_name\",\"label\",\"Num_Documents\", \"Perc_Documents\"]\n",
    "lda_inform = lda_inform[[\"Topic_Num\",\"Keywords\",\"Num_Documents\",\"Perc_Documents\"]]\n",
    "lda_inform\n",
    "#lda_inform.Topic_Num = lda_inform.Topic_Num.astype(int)\n",
    "lda_inform['Topic_Num'] =lda_inform['Topic_Num'] +1\n",
    "lda_inform.Topic_Num = lda_inform.Topic_Num.astype(str)\n",
    "lda_inform['Topic_Num'] =lda_inform['Topic_Num'].str.split('.').str[0]\n",
    "df_topic_tweet['Dominant_Topic'] =df_topic_tweet['Dominant_Topic'] +1\n",
    "df_topic_tweet.Dominant_Topic = df_topic_tweet.Dominant_Topic.astype(str)\n",
    "df_topic_tweet['Dominant_Topic'] =df_topic_tweet['Dominant_Topic'].str.split('.').str[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorGPUGPU",
   "language": "python",
   "name": "tensorgpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
